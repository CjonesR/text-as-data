{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "# import numpy as np\n",
    "# import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Set plt parameters\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams[\"figure.figsize\"] = (10,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the data into a list of strings\n",
    "screenplays = []\n",
    "for p in Path('../queue/screenplays/').glob('*.txt'):\n",
    "    with open(p, encoding=\"utf8\", errors='ignore') as f:\n",
    "        contents = f.read()\n",
    "        screenplays.append(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# While we're at it, let's grab file names\n",
    "titles= []\n",
    "for p in Path('../queue/screenplays/').glob('*.txt'):\n",
    "    with open(p, encoding=\"utf8\", errors='ignore') as f:\n",
    "        title = p.name[:-4]\n",
    "        titles.append(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `%%time` cell magic allows us to see how long a cell takes to run. Please note that it must come before anything else in the cell, even comments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2858\n"
     ]
    }
   ],
   "source": [
    "print(len(screenplays))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "143,000 dimensions is *a lot* of dimensions. Since we are topic modeling this, let's see what we can do to reduce the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26 s, sys: 164 ms, total: 26.2 s\n",
      "Wall time: 26.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2858, 47208)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Vectorize our texts while removing function words\n",
    "# and words that occur in only one text\n",
    "vectorizer = TfidfVectorizer(lowercase = True,\n",
    "                             min_df = 10,\n",
    "                             stop_words='english')\n",
    "\n",
    "# fit the model to the data \n",
    "matrix = vectorizer.fit_transform(screenplays)\n",
    "\n",
    "# We'll need these later\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "# see how many features we have\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min, sys: 38.6 s, total: 7min 39s\n",
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "wcss = [] \n",
    "for i in range(1, 30): \n",
    "    kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n",
    "    kmeans.fit(matrix) \n",
    "    wcss.append(kmeans.inertia_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Vectorize our texts while removing function words\n",
    "# and words that occur in only one text\n",
    "vectorizer = TfidfVectorizer(lowercase = True,\n",
    "                             min_df = 2,\n",
    "                             stop_words='english')\n",
    "\n",
    "# fit the model to the data \n",
    "matrix = vectorizer.fit_transform(screenplays)\n",
    "\n",
    "# We'll need these later\n",
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "\n",
    "# see how many features we have\n",
    "matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1, 30), wcss)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('WCSS') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters = 20, init = \"k-means++\", random_state = 42)\n",
    "y_kmeans = kmeans.fit_predict(matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
